{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e3e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV = r\"/home/abhayadana/Downloads/SummerLowStatureSampling_pt_2025.csv\"\n",
    "OUTPUT_DIR = r\"/home/abhayadana/Documents/GitHub/SLSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b202e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kernel categorical spatial interpolation per strManagementUnit\n",
    "with:\n",
    "- spatial block CV bandwidth selection\n",
    "- probability rasters per class\n",
    "- categorical winner raster (with uncertainty threshold + MMU)\n",
    "- masking to the ENVELOPE of sample points (convex hull, optional buffer)\n",
    "\n",
    "INPUT\n",
    "- CSV fields:\n",
    "    strManagementUnit\n",
    "    strAveHeight_cm_PctCover\n",
    "    UTM_X\n",
    "    UTM_Y\n",
    "- CRS assumed: UTM Zone 10, NAD83, meters (EPSG:26910)\n",
    "\n",
    "OUTPUT (per unit folder)\n",
    "- prob_<Class>.tif (float32, nodata=NaN)\n",
    "- p_max_confidence.tif (float32, nodata=NaN)\n",
    "- categorical_winner.tif (uint8, nodata=0; 0=Uncertain)\n",
    "- metadata.json\n",
    "\n",
    "DEPENDENCIES\n",
    "- numpy, pandas\n",
    "- rasterio\n",
    "- scipy recommended (KD-tree + MMU + convex hull fallback)\n",
    "- shapely optional (preferred for convex hull + buffering)\n",
    "- scikit-learn optional fallback for neighbor search if scipy is missing\n",
    "\n",
    "NOTES\n",
    "- \"Envelope of sample points\" is implemented as a convex hull polygon around the\n",
    "  points (optionally buffered), then rasters are masked outside the hull.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# User parameters\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "INPUT_CSV = r\"/home/abhayadana/Downloads/SummerLowStatureSampling_pt_2025.csv\"\n",
    "OUTPUT_DIR = r\"/home/abhayadana/Documents/GitHub/SLSS\"\n",
    "\n",
    "GRID_CELL_SIZE_M = 1.0\n",
    "\n",
    "CANDIDATE_BANDWIDTHS_M = [3, 5, 8, 12, 20]\n",
    "SEARCH_RADIUS_FACTOR = 3.0\n",
    "\n",
    "BLOCK_CV_BLOCK_SIZE_M = 30.0\n",
    "BLOCK_CV_FOLDS = 5\n",
    "\n",
    "UNCERTAIN_TOLERANCE = 0.50\n",
    "MMU_CELLS = 16\n",
    "\n",
    "# Grid extent: bbox of points (required for a raster transform), then mask outside hull.\n",
    "EXTENT_BUFFER_M = 0.0\n",
    "\n",
    "# Kernel type: \"gaussian\" or \"exponential\"\n",
    "KERNEL = \"gaussian\"\n",
    "\n",
    "# If a grid cell has no neighbors within search radius:\n",
    "# True -> prob rasters are NaN; categorical becomes 0 (Uncertain) there\n",
    "NO_NEIGHBOR_AS_NAN = True\n",
    "\n",
    "# Mask to envelope (convex hull) of sample points\n",
    "USE_POINT_ENVELOPE_MASK = True\n",
    "ENVELOPE_TYPE = \"convex_hull\"  # currently only convex_hull\n",
    "ENVELOPE_BUFFER_M = 0.0        # optional outward buffer in meters (e.g., 5.0)\n",
    "\n",
    "# CRS for output rasters\n",
    "CRS_EPSG = 26910\n",
    "\n",
    "EPS = 1e-12  # numerical safety for log-loss / normalization\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Constants: fixed class order and codes\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "CLASSES = [\n",
    "    \"Short Open\",\n",
    "    \"Tall Open\",\n",
    "    \"Mid Mod\",\n",
    "    \"Short Dense\",\n",
    "    \"Tall Dense\",\n",
    "]\n",
    "CLASS_TO_CODE = {cls: i + 1 for i, cls in enumerate(CLASSES)}\n",
    "CODE_TO_CLASS = {0: \"Uncertain\", **{i + 1: cls for i, cls in enumerate(CLASSES)}}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utilities\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def safe_name(name: str) -> str:\n",
    "    \"\"\"Make a safe folder/file stem from a string.\"\"\"\n",
    "    name = str(name).strip()\n",
    "    name = re.sub(r\"[^\\w\\-]+\", \"_\", name)\n",
    "    name = re.sub(r\"_+\", \"_\", name).strip(\"_\")\n",
    "    return name or \"unit\"\n",
    "\n",
    "\n",
    "def gaussian_kernel(d: np.ndarray, h: float) -> np.ndarray:\n",
    "    \"\"\"Gaussian kernel weights for distances d and bandwidth h.\"\"\"\n",
    "    z = d / max(h, EPS)\n",
    "    return np.exp(-0.5 * z * z)\n",
    "\n",
    "\n",
    "def exponential_kernel(d: np.ndarray, h: float) -> np.ndarray:\n",
    "    \"\"\"Exponential kernel weights for distances d and bandwidth h.\"\"\"\n",
    "    z = d / max(h, EPS)\n",
    "    return np.exp(-z)\n",
    "\n",
    "\n",
    "def get_kernel_fn(kernel: str):\n",
    "    \"\"\"Return kernel function by name.\"\"\"\n",
    "    k = kernel.lower().strip()\n",
    "    if k == \"gaussian\":\n",
    "        return gaussian_kernel\n",
    "    if k in (\"exponential\", \"exp\"):\n",
    "        return exponential_kernel\n",
    "    raise ValueError(f\"Unknown kernel: {kernel!r}. Use 'gaussian' or 'exponential'.\")\n",
    "\n",
    "\n",
    "def build_grid(\n",
    "    xmin: float,\n",
    "    ymin: float,\n",
    "    xmax: float,\n",
    "    ymax: float,\n",
    "    cell_size: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray, rasterio.Affine]:\n",
    "    \"\"\"\n",
    "    Create a raster grid covering the bounding box.\n",
    "\n",
    "    Returns:\n",
    "    - x_centers: 1D array of x cell centers (width)\n",
    "    - y_centers: 1D array of y cell centers (height)\n",
    "    - transform: affine transform for rasterio\n",
    "    \"\"\"\n",
    "    width = int(math.ceil((xmax - xmin) / cell_size))\n",
    "    height = int(math.ceil((ymax - ymin) / cell_size))\n",
    "\n",
    "    # Upper-left corner at (xmin, ymax)\n",
    "    transform = from_origin(xmin, ymax, cell_size, cell_size)\n",
    "\n",
    "    x_centers = xmin + (np.arange(width) + 0.5) * cell_size\n",
    "    y_centers = ymax - (np.arange(height) + 0.5) * cell_size\n",
    "    return x_centers, y_centers, transform\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UnitData:\n",
    "    \"\"\"Container for one management unit's point data.\"\"\"\n",
    "    unit: str\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "    y_code: np.ndarray\n",
    "    present_codes: List[int]\n",
    "\n",
    "\n",
    "def read_points(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV and validate required columns.\"\"\"\n",
    "    df = pd.read_csv(csv_path, dtype=str)\n",
    "\n",
    "    required = {\"strManagementUnit\", \"strAveHeight_cm_PctCover\", \"UTM_X\", \"UTM_Y\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    df[\"UTM_X\"] = pd.to_numeric(df[\"UTM_X\"], errors=\"coerce\")\n",
    "    df[\"UTM_Y\"] = pd.to_numeric(df[\"UTM_Y\"], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(\n",
    "        subset=[\"UTM_X\", \"UTM_Y\", \"strManagementUnit\", \"strAveHeight_cm_PctCover\"]\n",
    "    ).copy()\n",
    "\n",
    "    df[\"strAveHeight_cm_PctCover\"] = df[\"strAveHeight_cm_PctCover\"].astype(str).str.strip()\n",
    "    df = df[df[\"strAveHeight_cm_PctCover\"].isin(CLASSES)].copy()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No valid points after filtering to known classes and valid coordinates.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_by_unit(df: pd.DataFrame) -> List[UnitData]:\n",
    "    \"\"\"Split dataframe into per-unit UnitData objects.\"\"\"\n",
    "    units: List[UnitData] = []\n",
    "    for unit, g in df.groupby(\"strManagementUnit\", sort=True):\n",
    "        x = g[\"UTM_X\"].to_numpy(dtype=float)\n",
    "        y = g[\"UTM_Y\"].to_numpy(dtype=float)\n",
    "        y_code = g[\"strAveHeight_cm_PctCover\"].map(CLASS_TO_CODE).to_numpy(dtype=int)\n",
    "        present = sorted(np.unique(y_code).tolist())\n",
    "        units.append(UnitData(unit=str(unit), x=x, y=y, y_code=y_code, present_codes=present))\n",
    "    return units\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Envelope (convex hull) masking\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def build_point_envelope_geometry(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    envelope_type: str = \"convex_hull\",\n",
    "    buffer_m: float = 0.0,\n",
    ") -> Sequence[dict]:\n",
    "    \"\"\"\n",
    "    Build an envelope geometry (convex hull) around points, optionally buffered.\n",
    "\n",
    "    Returns GeoJSON-like geometries suitable for rasterio.features.geometry_mask.\n",
    "    \"\"\"\n",
    "    envelope_type = envelope_type.lower().strip()\n",
    "    if envelope_type != \"convex_hull\":\n",
    "        raise ValueError(\"Only envelope_type='convex_hull' is supported.\")\n",
    "\n",
    "    pts = np.column_stack([x, y]).astype(float)\n",
    "\n",
    "    # Preferred: shapely\n",
    "    try:\n",
    "        from shapely.geometry import MultiPoint  # type: ignore\n",
    "        from shapely.geometry import mapping  # type: ignore\n",
    "\n",
    "        hull = MultiPoint(pts).convex_hull\n",
    "        if buffer_m and float(buffer_m) != 0.0:\n",
    "            hull = hull.buffer(float(buffer_m))\n",
    "        return [mapping(hull)]\n",
    "    except Exception:\n",
    "        # Fallback: scipy ConvexHull -> polygon\n",
    "        try:\n",
    "            from scipy.spatial import ConvexHull  # type: ignore\n",
    "        except Exception as exc:\n",
    "            raise ImportError(\n",
    "                \"To use envelope masking, install shapely (preferred) or scipy.\"\n",
    "            ) from exc\n",
    "\n",
    "        hull = ConvexHull(pts)\n",
    "        ring = pts[hull.vertices].tolist()\n",
    "        ring.append(ring[0])\n",
    "\n",
    "        geom = {\"type\": \"Polygon\", \"coordinates\": [ring]}\n",
    "        return [geom]\n",
    "\n",
    "\n",
    "def apply_envelope_mask(\n",
    "    prob_stack: np.ndarray,\n",
    "    p_max: np.ndarray,\n",
    "    winner: np.ndarray,\n",
    "    transform: rasterio.Affine,\n",
    "    envelope_geoms: Sequence[dict],\n",
    "    nodata_float: float = np.nan,\n",
    "    nodata_cat: int = 0,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Mask rasters outside envelope geometry.\n",
    "\n",
    "    - prob_stack: (H, W, 5)\n",
    "    - p_max: (H, W)\n",
    "    - winner: (H, W)\n",
    "\n",
    "    Outside envelope:\n",
    "    - prob_stack -> NaN\n",
    "    - p_max -> NaN\n",
    "    - winner -> 0\n",
    "    \"\"\"\n",
    "    h, w = winner.shape\n",
    "\n",
    "    # geometry_mask returns True where pixels should be masked.\n",
    "    # invert=True returns True for pixels INSIDE the geometry.\n",
    "    inside = geometry_mask(\n",
    "        geometries=envelope_geoms,\n",
    "        out_shape=(h, w),\n",
    "        transform=transform,\n",
    "        invert=True,\n",
    "        all_touched=False,\n",
    "    )\n",
    "    outside = ~inside\n",
    "\n",
    "    prob_out = prob_stack.copy()\n",
    "    pmax_out = p_max.copy()\n",
    "    win_out = winner.copy()\n",
    "\n",
    "    prob_out[outside, :] = nodata_float\n",
    "    pmax_out[outside] = nodata_float\n",
    "    win_out[outside] = nodata_cat\n",
    "\n",
    "    return prob_out, pmax_out, win_out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Neighbor search backend\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class NeighborIndex:\n",
    "    \"\"\"\n",
    "    KD-tree neighbor index with radius queries.\n",
    "\n",
    "    Prefers scipy.spatial.cKDTree; falls back to sklearn NearestNeighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray):\n",
    "        pts = np.column_stack([x, y]).astype(float)\n",
    "        self.pts = pts\n",
    "        self._backend = None\n",
    "        self._tree = None\n",
    "\n",
    "        try:\n",
    "            from scipy.spatial import cKDTree  # type: ignore\n",
    "\n",
    "            self._backend = \"scipy\"\n",
    "            self._tree = cKDTree(pts)\n",
    "        except Exception:\n",
    "            try:\n",
    "                from sklearn.neighbors import NearestNeighbors  # type: ignore\n",
    "\n",
    "                self._backend = \"sklearn\"\n",
    "                self._tree = NearestNeighbors(algorithm=\"ball_tree\")\n",
    "                self._tree.fit(pts)\n",
    "            except Exception as exc:\n",
    "                raise ImportError(\n",
    "                    \"Need scipy (recommended) or scikit-learn for neighbor search.\"\n",
    "                ) from exc\n",
    "\n",
    "    def query_radius_indices(self, targets: np.ndarray, radius: float) -> List[np.ndarray]:\n",
    "        \"\"\"Return neighbor indices within radius for each target point.\"\"\"\n",
    "        if self._backend == \"scipy\":\n",
    "            return self._tree.query_ball_point(targets, r=radius)  # type: ignore\n",
    "\n",
    "        # sklearn fallback: kNN then filter by radius (approx; can be slow)\n",
    "        n = self.pts.shape[0]\n",
    "        k = min(n, 5000)\n",
    "        dists, inds = self._tree.kneighbors(targets, n_neighbors=k, return_distance=True)  # type: ignore\n",
    "\n",
    "        out: List[np.ndarray] = []\n",
    "        for di, ii in zip(dists, inds):\n",
    "            out.append(ii[di <= radius])\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Kernel probability prediction\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def predict_probabilities(\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    train_code: np.ndarray,\n",
    "    present_codes: List[int],\n",
    "    targets_xy: np.ndarray,\n",
    "    bandwidth_m: float,\n",
    "    search_radius_m: float,\n",
    "    kernel: str,\n",
    "    no_neighbor_as_nan: bool = True,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Predict class probabilities at targets using kernel-weighted frequencies.\n",
    "\n",
    "    Returns:\n",
    "        probs: (n_targets, 5) probabilities in CLASSES order.\n",
    "               If no neighbors within radius:\n",
    "                 - NaNs if no_neighbor_as_nan=True\n",
    "                 - zeros otherwise\n",
    "    \"\"\"\n",
    "    kernel_fn = get_kernel_fn(kernel)\n",
    "    idx = NeighborIndex(train_x, train_y)\n",
    "    neighbors = idx.query_radius_indices(targets_xy, radius=search_radius_m)\n",
    "\n",
    "    n_targets = targets_xy.shape[0]\n",
    "    probs = np.zeros((n_targets, len(CLASSES)), dtype=float)\n",
    "\n",
    "    train_xy = np.column_stack([train_x, train_y]).astype(float)\n",
    "    present_set = set(present_codes)\n",
    "    absent_codes = [c for c in range(1, 6) if c not in present_set]\n",
    "\n",
    "    for i in range(n_targets):\n",
    "        nn = neighbors[i]\n",
    "        if len(nn) == 0:\n",
    "            probs[i, :] = np.nan if no_neighbor_as_nan else 0.0\n",
    "            continue\n",
    "\n",
    "        d = np.sqrt(np.sum((train_xy[nn] - targets_xy[i]) ** 2, axis=1))\n",
    "        w = kernel_fn(d, h=bandwidth_m)\n",
    "        w_sum = float(np.sum(w))\n",
    "\n",
    "        if w_sum <= 0.0 or not np.isfinite(w_sum):\n",
    "            probs[i, :] = np.nan if no_neighbor_as_nan else 0.0\n",
    "            continue\n",
    "\n",
    "        for code in present_codes:\n",
    "            mask = train_code[nn] == code\n",
    "            probs[i, code - 1] = float(np.sum(w[mask]) / w_sum) if np.any(mask) else 0.0\n",
    "\n",
    "        for code in absent_codes:\n",
    "            probs[i, code - 1] = 0.0\n",
    "\n",
    "        s = np.nansum(probs[i, :])\n",
    "        if s > 0:\n",
    "            probs[i, :] = probs[i, :] / s\n",
    "        else:\n",
    "            probs[i, :] = np.nan if no_neighbor_as_nan else 0.0\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Spatial block CV bandwidth selection\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def assign_blocks(x: np.ndarray, y: np.ndarray, block_size_m: float) -> np.ndarray:\n",
    "    \"\"\"Assign each point to a spatial block id based on a block grid.\"\"\"\n",
    "    xmin = float(np.min(x))\n",
    "    ymin = float(np.min(y))\n",
    "    bx = np.floor((x - xmin) / block_size_m).astype(int)\n",
    "    by = np.floor((y - ymin) / block_size_m).astype(int)\n",
    "    return bx.astype(np.int64) * 1_000_000 + by.astype(np.int64)\n",
    "\n",
    "\n",
    "def make_block_folds(block_ids: np.ndarray, n_folds: int, seed: int = 42) -> List[np.ndarray]:\n",
    "    \"\"\"Split unique block ids into folds; return boolean masks for test points.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    unique_blocks = np.unique(block_ids)\n",
    "    rng.shuffle(unique_blocks)\n",
    "\n",
    "    folds: List[np.ndarray] = []\n",
    "    parts = np.array_split(unique_blocks, n_folds)\n",
    "    for blocks_in_fold in parts:\n",
    "        folds.append(np.isin(block_ids, blocks_in_fold))\n",
    "    return folds\n",
    "\n",
    "\n",
    "def log_loss_from_probs(true_codes: np.ndarray, probs: np.ndarray, eps: float = EPS) -> float:\n",
    "    \"\"\"Multiclass log loss with probs shape (n, 5), true_codes in 1..5.\"\"\"\n",
    "    p_true = probs[np.arange(len(true_codes)), true_codes - 1]\n",
    "    p_true = np.clip(p_true, eps, 1.0)\n",
    "    return float(np.mean(-np.log(p_true)))\n",
    "\n",
    "\n",
    "def select_bandwidth_by_block_cv(\n",
    "    unit_data: UnitData,\n",
    "    candidate_bandwidths_m: Iterable[float],\n",
    "    search_radius_factor: float,\n",
    "    block_size_m: float,\n",
    "    kernel: str,\n",
    "    n_folds: int = 5,\n",
    "    seed: int = 42,\n",
    ") -> float:\n",
    "    \"\"\"Pick bandwidth minimizing spatial block CV log loss for one unit.\"\"\"\n",
    "    x, y, y_code = unit_data.x, unit_data.y, unit_data.y_code\n",
    "    cand = sorted([float(h) for h in candidate_bandwidths_m])\n",
    "\n",
    "    if len(x) < 10:\n",
    "        return float(cand[len(cand) // 2])\n",
    "\n",
    "    block_ids = assign_blocks(x, y, block_size_m=block_size_m)\n",
    "    folds = make_block_folds(block_ids, n_folds=n_folds, seed=seed)\n",
    "\n",
    "    best_h: Optional[float] = None\n",
    "    best_score = np.inf\n",
    "\n",
    "    for h in cand:\n",
    "        r = float(search_radius_factor * h)\n",
    "        fold_scores: List[float] = []\n",
    "\n",
    "        for test_mask in folds:\n",
    "            train_mask = ~test_mask\n",
    "            if np.sum(train_mask) < 2 or np.sum(test_mask) < 1:\n",
    "                continue\n",
    "\n",
    "            probs = predict_probabilities(\n",
    "                train_x=x[train_mask],\n",
    "                train_y=y[train_mask],\n",
    "                train_code=y_code[train_mask],\n",
    "                present_codes=unit_data.present_codes,\n",
    "                targets_xy=np.column_stack([x[test_mask], y[test_mask]]).astype(float),\n",
    "                bandwidth_m=h,\n",
    "                search_radius_m=r,\n",
    "                kernel=kernel,\n",
    "                no_neighbor_as_nan=False,  # keep finite for CV scoring\n",
    "            )\n",
    "\n",
    "            probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            s = probs.sum(axis=1, keepdims=True)\n",
    "            s[s == 0] = 1.0\n",
    "            probs = probs / s\n",
    "            probs = np.clip(probs, EPS, 1.0)\n",
    "            probs = probs / probs.sum(axis=1, keepdims=True)\n",
    "\n",
    "            fold_scores.append(log_loss_from_probs(y_code[test_mask], probs, eps=EPS))\n",
    "\n",
    "        if not fold_scores:\n",
    "            continue\n",
    "\n",
    "        mean_score = float(np.mean(fold_scores))\n",
    "        if mean_score < best_score:\n",
    "            best_score = mean_score\n",
    "            best_h = h\n",
    "\n",
    "    return float(best_h) if best_h is not None else float(cand[len(cand) // 2])\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# MMU cleanup for categorical raster\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def fill_uncertain_by_majority(cat: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Fill zeros using 3x3 neighborhood majority class (excluding zero).\"\"\"\n",
    "    try:\n",
    "        from scipy import ndimage  # type: ignore\n",
    "    except Exception:\n",
    "        return cat\n",
    "\n",
    "    out = cat.copy()\n",
    "    uncertain = out == 0\n",
    "    if not np.any(uncertain):\n",
    "        return out\n",
    "\n",
    "    kernel = np.ones((3, 3), dtype=int)\n",
    "    class_counts = []\n",
    "    for code in range(1, 6):\n",
    "        m = (out == code).astype(int)\n",
    "        class_counts.append(ndimage.convolve(m, kernel, mode=\"nearest\"))\n",
    "\n",
    "    counts = np.stack(class_counts, axis=0)  # (5, H, W)\n",
    "    winner = np.argmax(counts, axis=0) + 1\n",
    "    max_count = np.max(counts, axis=0)\n",
    "\n",
    "    fillable = uncertain & (max_count > 0)\n",
    "    out[fillable] = winner[fillable].astype(out.dtype)\n",
    "    return out\n",
    "\n",
    "\n",
    "def mmu_cleanup(cat: np.ndarray, mmu_cells: int, n_iters: int = 5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Remove patches smaller than mmu_cells for each class (>0), fill by neighborhood majority.\n",
    "    Requires scipy.ndimage; if missing, returns input unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy import ndimage  # type: ignore\n",
    "    except Exception:\n",
    "        print(\"WARNING: scipy not available; skipping MMU cleanup.\")\n",
    "        return cat\n",
    "\n",
    "    out = cat.copy()\n",
    "    structure = np.ones((3, 3), dtype=int)  # 8-connectivity\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        changed = False\n",
    "        for code in range(1, 6):\n",
    "            mask = out == code\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "\n",
    "            labeled, nlab = ndimage.label(mask, structure=structure)\n",
    "            if nlab == 0:\n",
    "                continue\n",
    "\n",
    "            sizes = np.bincount(labeled.ravel())\n",
    "            small_labels = np.where((sizes < mmu_cells) & (np.arange(len(sizes)) != 0))[0]\n",
    "            if len(small_labels) == 0:\n",
    "                continue\n",
    "\n",
    "            small_mask = np.isin(labeled, small_labels)\n",
    "            if np.any(small_mask):\n",
    "                out[small_mask] = 0\n",
    "                changed = True\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "        out = fill_uncertain_by_majority(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Raster writing\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def write_geotiff(\n",
    "    path: Path,\n",
    "    array: np.ndarray,\n",
    "    transform: rasterio.Affine,\n",
    "    crs_epsg: int,\n",
    "    nodata: Optional[float] = None,\n",
    "    dtype: Optional[str] = None,\n",
    ") -> None:\n",
    "    \"\"\"Write a single-band GeoTIFF.\"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if dtype is None:\n",
    "        dtype = str(array.dtype)\n",
    "\n",
    "    height, width = array.shape\n",
    "    profile = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"count\": 1,\n",
    "        \"dtype\": dtype,\n",
    "        \"crs\": rasterio.crs.CRS.from_epsg(crs_epsg),\n",
    "        \"transform\": transform,\n",
    "        \"compress\": \"deflate\",\n",
    "        \"predictor\": 2 if np.issubdtype(array.dtype, np.floating) else 1,\n",
    "        \"tiled\": True,\n",
    "        \"blockxsize\": 256,\n",
    "        \"blockysize\": 256,\n",
    "    }\n",
    "    if nodata is not None:\n",
    "        profile[\"nodata\"] = nodata\n",
    "\n",
    "    with rasterio.open(path, \"w\", **profile) as dst:\n",
    "        dst.write(array, 1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main per-unit processing\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def unit_extent(unit_data: UnitData, buffer_m: float = 0.0) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Compute (xmin, ymin, xmax, ymax) extent from points, expanded by buffer.\"\"\"\n",
    "    xmin = float(np.min(unit_data.x)) - buffer_m\n",
    "    ymin = float(np.min(unit_data.y)) - buffer_m\n",
    "    xmax = float(np.max(unit_data.x)) + buffer_m\n",
    "    ymax = float(np.max(unit_data.y)) + buffer_m\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def predict_unit_rasters(\n",
    "    unit_data: UnitData,\n",
    "    output_dir: Path,\n",
    "    cell_size_m: float,\n",
    "    bandwidth_m: float,\n",
    "    search_radius_factor: float,\n",
    "    kernel: str,\n",
    "    uncertain_tolerance: float,\n",
    "    mmu_cells: int,\n",
    "    extent_buffer_m: float = 0.0,\n",
    "    no_neighbor_as_nan: bool = True,\n",
    "    crs_epsg: int = CRS_EPSG,\n",
    "    use_envelope_mask: bool = True,\n",
    "    envelope_type: str = \"convex_hull\",\n",
    "    envelope_buffer_m: float = 0.0,\n",
    ") -> None:\n",
    "    \"\"\"Predict and write rasters for one unit.\"\"\"\n",
    "    unit_name = safe_name(unit_data.unit)\n",
    "    unit_out = output_dir / unit_name\n",
    "    unit_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    xmin, ymin, xmax, ymax = unit_extent(unit_data, buffer_m=extent_buffer_m)\n",
    "    x_centers, y_centers, transform = build_grid(xmin, ymin, xmax, ymax, cell_size=cell_size_m)\n",
    "    width = len(x_centers)\n",
    "    height = len(y_centers)\n",
    "\n",
    "    xx, yy = np.meshgrid(x_centers, y_centers)\n",
    "    targets = np.column_stack([xx.ravel(), yy.ravel()]).astype(float)\n",
    "\n",
    "    search_radius_m = float(search_radius_factor * bandwidth_m)\n",
    "\n",
    "    probs = predict_probabilities(\n",
    "        train_x=unit_data.x,\n",
    "        train_y=unit_data.y,\n",
    "        train_code=unit_data.y_code,\n",
    "        present_codes=unit_data.present_codes,\n",
    "        targets_xy=targets,\n",
    "        bandwidth_m=float(bandwidth_m),\n",
    "        search_radius_m=search_radius_m,\n",
    "        kernel=kernel,\n",
    "        no_neighbor_as_nan=no_neighbor_as_nan,\n",
    "    )\n",
    "\n",
    "    prob_stack = probs.reshape((height, width, 5)).astype(np.float32)\n",
    "\n",
    "    # Renormalize per cell (keep NaN for all-NaN)\n",
    "    s = np.nansum(prob_stack, axis=2, keepdims=True)\n",
    "    s = np.where(s == 0, np.nan, s)\n",
    "    prob_stack = prob_stack / s\n",
    "\n",
    "    # Safe categorical + confidence (handles all-NaN cells)\n",
    "    all_nan = np.all(~np.isfinite(prob_stack), axis=2)\n",
    "\n",
    "    p_max = np.nanmax(prob_stack, axis=2).astype(np.float32)\n",
    "    p_max[all_nan] = np.nan\n",
    "\n",
    "    prob_for_argmax = np.where(np.isfinite(prob_stack), prob_stack, -np.inf)\n",
    "    winner = (np.argmax(prob_for_argmax, axis=2) + 1).astype(np.uint8)\n",
    "    winner[all_nan] = 0\n",
    "\n",
    "    # Uncertainty threshold\n",
    "    if uncertain_tolerance is not None:\n",
    "        uncertain_mask = (p_max < float(uncertain_tolerance)) | ~np.isfinite(p_max)\n",
    "        winner[uncertain_mask] = 0\n",
    "\n",
    "    # Mask outside point envelope (convex hull)\n",
    "    if use_envelope_mask:\n",
    "        envelope_geoms = build_point_envelope_geometry(\n",
    "            x=unit_data.x,\n",
    "            y=unit_data.y,\n",
    "            envelope_type=envelope_type,\n",
    "            buffer_m=envelope_buffer_m,\n",
    "        )\n",
    "        prob_stack, p_max, winner = apply_envelope_mask(\n",
    "            prob_stack=prob_stack,\n",
    "            p_max=p_max,\n",
    "            winner=winner,\n",
    "            transform=transform,\n",
    "            envelope_geoms=envelope_geoms,\n",
    "            nodata_float=np.nan,\n",
    "            nodata_cat=0,\n",
    "        )\n",
    "\n",
    "    # MMU cleanup (categorical only, after masking)\n",
    "    if mmu_cells and int(mmu_cells) > 1:\n",
    "        winner = mmu_cleanup(winner, mmu_cells=int(mmu_cells)).astype(np.uint8)\n",
    "\n",
    "    # Write outputs\n",
    "    nodata_float = np.nan\n",
    "\n",
    "    for i, cls in enumerate(CLASSES):\n",
    "        out_path = unit_out / f\"prob_{safe_name(cls)}.tif\"\n",
    "        write_geotiff(\n",
    "            out_path,\n",
    "            prob_stack[:, :, i].astype(np.float32),\n",
    "            transform=transform,\n",
    "            crs_epsg=crs_epsg,\n",
    "            nodata=nodata_float,\n",
    "            dtype=\"float32\",\n",
    "        )\n",
    "\n",
    "    write_geotiff(\n",
    "        unit_out / \"p_max_confidence.tif\",\n",
    "        p_max.astype(np.float32),\n",
    "        transform=transform,\n",
    "        crs_epsg=crs_epsg,\n",
    "        nodata=nodata_float,\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "\n",
    "    write_geotiff(\n",
    "        unit_out / \"categorical_winner.tif\",\n",
    "        winner.astype(np.uint8),\n",
    "        transform=transform,\n",
    "        crs_epsg=crs_epsg,\n",
    "        nodata=0,\n",
    "        dtype=\"uint8\",\n",
    "    )\n",
    "\n",
    "    meta = {\n",
    "        \"strManagementUnit\": unit_data.unit,\n",
    "        \"bandwidth_m\": float(bandwidth_m),\n",
    "        \"search_radius_m\": float(search_radius_m),\n",
    "        \"grid_cell_size_m\": float(cell_size_m),\n",
    "        \"kernel\": kernel,\n",
    "        \"uncertain_tolerance\": float(uncertain_tolerance),\n",
    "        \"mmu_cells\": int(mmu_cells),\n",
    "        \"use_point_envelope_mask\": bool(use_envelope_mask),\n",
    "        \"envelope_type\": envelope_type,\n",
    "        \"envelope_buffer_m\": float(envelope_buffer_m),\n",
    "        \"extent_buffer_m\": float(extent_buffer_m),\n",
    "        \"class_to_code\": CLASS_TO_CODE,\n",
    "        \"code_to_class\": CODE_TO_CLASS,\n",
    "        \"present_codes_in_unit\": unit_data.present_codes,\n",
    "    }\n",
    "    (unit_out / \"metadata.json\").write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "\n",
    "def run_workflow(\n",
    "    input_csv: str,\n",
    "    output_dir: str,\n",
    "    grid_cell_size_m: float,\n",
    "    candidate_bandwidths_m: Iterable[float],\n",
    "    search_radius_factor: float,\n",
    "    block_cv_block_size_m: float,\n",
    "    uncertain_tolerance: float,\n",
    "    mmu_cells: int,\n",
    "    extent_buffer_m: float = 0.0,\n",
    "    kernel: str = \"gaussian\",\n",
    "    no_neighbor_as_nan: bool = True,\n",
    "    crs_epsg: int = CRS_EPSG,\n",
    "    use_envelope_mask: bool = True,\n",
    "    envelope_type: str = \"convex_hull\",\n",
    "    envelope_buffer_m: float = 0.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run per-unit workflow. Returns a summary dataframe with selected bandwidths.\n",
    "    \"\"\"\n",
    "    out_dir = Path(output_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = read_points(input_csv)\n",
    "    units = split_by_unit(df)\n",
    "\n",
    "    results = []\n",
    "    for u in units:\n",
    "        print(f\"\\n--- Unit: {u.unit} (n={len(u.x)}) ---\")\n",
    "        print(f\"Present classes: {[CODE_TO_CLASS[c] for c in u.present_codes]}\")\n",
    "\n",
    "        best_h = select_bandwidth_by_block_cv(\n",
    "            unit_data=u,\n",
    "            candidate_bandwidths_m=candidate_bandwidths_m,\n",
    "            search_radius_factor=search_radius_factor,\n",
    "            block_size_m=block_cv_block_size_m,\n",
    "            kernel=kernel,\n",
    "            n_folds=BLOCK_CV_FOLDS,\n",
    "            seed=42,\n",
    "        )\n",
    "        print(f\"Selected bandwidth (m): {best_h}\")\n",
    "\n",
    "        predict_unit_rasters(\n",
    "            unit_data=u,\n",
    "            output_dir=out_dir,\n",
    "            cell_size_m=grid_cell_size_m,\n",
    "            bandwidth_m=best_h,\n",
    "            search_radius_factor=search_radius_factor,\n",
    "            kernel=kernel,\n",
    "            uncertain_tolerance=uncertain_tolerance,\n",
    "            mmu_cells=mmu_cells,\n",
    "            extent_buffer_m=extent_buffer_m,\n",
    "            no_neighbor_as_nan=no_neighbor_as_nan,\n",
    "            crs_epsg=crs_epsg,\n",
    "            use_envelope_mask=use_envelope_mask,\n",
    "            envelope_type=envelope_type,\n",
    "            envelope_buffer_m=envelope_buffer_m,\n",
    "        )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"strManagementUnit\": u.unit,\n",
    "                \"n_points\": int(len(u.x)),\n",
    "                \"present_classes\": \", \".join([CODE_TO_CLASS[c] for c in u.present_codes]),\n",
    "                \"selected_bandwidth_m\": float(best_h),\n",
    "                \"search_radius_m\": float(search_radius_factor * best_h),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary = pd.DataFrame(results).sort_values(\"strManagementUnit\").reset_index(drop=True)\n",
    "    summary_path = out_dir / \"unit_bandwidth_summary.csv\"\n",
    "    summary.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nWrote: {summary_path}\")\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7af14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Unit: 1NE (n=308) ---\n",
      "Present classes: ['Short Open', 'Mid Mod', 'Short Dense', 'Tall Dense']\n",
      "Selected bandwidth (m): 20.0\n",
      "\n",
      "--- Unit: 2NW_2NE_N (n=116) ---\n",
      "Present classes: ['Mid Mod', 'Tall Dense']\n",
      "Selected bandwidth (m): 20.0\n",
      "\n",
      "--- Unit: 2NW_2NE_S (n=61) ---\n",
      "Present classes: ['Mid Mod', 'Tall Dense']\n",
      "Selected bandwidth (m): 8.0\n",
      "\n",
      "--- Unit: 3NC_3NE_3C (n=865) ---\n",
      "Present classes: ['Short Open', 'Tall Open', 'Mid Mod', 'Short Dense', 'Tall Dense']\n",
      "Selected bandwidth (m): 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8263/1340728767.py:701: RuntimeWarning: All-NaN slice encountered\n",
      "  p_max = np.nanmax(prob_stack, axis=2).astype(np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Unit: 3S_4NE (n=1597) ---\n",
      "Present classes: ['Short Open', 'Tall Open', 'Mid Mod', 'Short Dense', 'Tall Dense']\n",
      "Selected bandwidth (m): 20.0\n",
      "\n",
      "--- Unit: 6N (n=105) ---\n",
      "Present classes: ['Mid Mod', 'Tall Dense']\n",
      "Selected bandwidth (m): 12.0\n",
      "\n",
      "Wrote: /home/abhayadana/Documents/GitHub/SLSS/unit_bandwidth_summary.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "strManagementUnit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_points",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "present_classes",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "selected_bandwidth_m",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "search_radius_m",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f08c7fb8-4aaf-48ed-9b93-73807c5c3792",
       "rows": [
        [
         "0",
         "1NE",
         "308",
         "Short Open, Mid Mod, Short Dense, Tall Dense",
         "20.0",
         "60.0"
        ],
        [
         "1",
         "2NW_2NE_N",
         "116",
         "Mid Mod, Tall Dense",
         "20.0",
         "60.0"
        ],
        [
         "2",
         "2NW_2NE_S",
         "61",
         "Mid Mod, Tall Dense",
         "8.0",
         "24.0"
        ],
        [
         "3",
         "3NC_3NE_3C",
         "865",
         "Short Open, Tall Open, Mid Mod, Short Dense, Tall Dense",
         "20.0",
         "60.0"
        ],
        [
         "4",
         "3S_4NE",
         "1597",
         "Short Open, Tall Open, Mid Mod, Short Dense, Tall Dense",
         "20.0",
         "60.0"
        ],
        [
         "5",
         "6N",
         "105",
         "Mid Mod, Tall Dense",
         "12.0",
         "36.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strManagementUnit</th>\n",
       "      <th>n_points</th>\n",
       "      <th>present_classes</th>\n",
       "      <th>selected_bandwidth_m</th>\n",
       "      <th>search_radius_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1NE</td>\n",
       "      <td>308</td>\n",
       "      <td>Short Open, Mid Mod, Short Dense, Tall Dense</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2NW_2NE_N</td>\n",
       "      <td>116</td>\n",
       "      <td>Mid Mod, Tall Dense</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2NW_2NE_S</td>\n",
       "      <td>61</td>\n",
       "      <td>Mid Mod, Tall Dense</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3NC_3NE_3C</td>\n",
       "      <td>865</td>\n",
       "      <td>Short Open, Tall Open, Mid Mod, Short Dense, T...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3S_4NE</td>\n",
       "      <td>1597</td>\n",
       "      <td>Short Open, Tall Open, Mid Mod, Short Dense, T...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6N</td>\n",
       "      <td>105</td>\n",
       "      <td>Mid Mod, Tall Dense</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  strManagementUnit  n_points  \\\n",
       "0               1NE       308   \n",
       "1         2NW_2NE_N       116   \n",
       "2         2NW_2NE_S        61   \n",
       "3        3NC_3NE_3C       865   \n",
       "4            3S_4NE      1597   \n",
       "5                6N       105   \n",
       "\n",
       "                                     present_classes  selected_bandwidth_m  \\\n",
       "0       Short Open, Mid Mod, Short Dense, Tall Dense                  20.0   \n",
       "1                                Mid Mod, Tall Dense                  20.0   \n",
       "2                                Mid Mod, Tall Dense                   8.0   \n",
       "3  Short Open, Tall Open, Mid Mod, Short Dense, T...                  20.0   \n",
       "4  Short Open, Tall Open, Mid Mod, Short Dense, T...                  20.0   \n",
       "5                                Mid Mod, Tall Dense                  12.0   \n",
       "\n",
       "   search_radius_m  \n",
       "0             60.0  \n",
       "1             60.0  \n",
       "2             24.0  \n",
       "3             60.0  \n",
       "4             60.0  \n",
       "5             36.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Run (execute this cell in your notebook)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "summary_df = run_workflow(\n",
    "    input_csv=INPUT_CSV,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    grid_cell_size_m=GRID_CELL_SIZE_M,\n",
    "    candidate_bandwidths_m=CANDIDATE_BANDWIDTHS_M,\n",
    "    search_radius_factor=SEARCH_RADIUS_FACTOR,\n",
    "    block_cv_block_size_m=BLOCK_CV_BLOCK_SIZE_M,\n",
    "    uncertain_tolerance=UNCERTAIN_TOLERANCE,\n",
    "    mmu_cells=MMU_CELLS,\n",
    "    extent_buffer_m=EXTENT_BUFFER_M,\n",
    "    kernel=KERNEL,\n",
    "    no_neighbor_as_nan=NO_NEIGHBOR_AS_NAN,\n",
    "    crs_epsg=CRS_EPSG,\n",
    ")\n",
    "summary_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
